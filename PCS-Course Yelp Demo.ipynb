{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Yelp Restaurant Reviews with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. A tour of the dataset\n",
    "1. Introduction to text processing with spaCy\n",
    "1. Automatic phrase modeling\n",
    "1. Topic modeling with LDA\n",
    "1. Visualizing topic models with pyLDAvis\n",
    "1. Word vector models with word2vec\n",
    "1. Visualizing word2vec with t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Yelp Dataset\n",
    "[**The Yelp Dataset**](https://www.yelp.com/dataset_challenge/) is a dataset published by the business review service [**Yelp**](http://yelp.com) for academic research and educational purposes.\n",
    "\n",
    "The current iteration of the Yelp dataset (as of this demo) consists of the following data:\n",
    "- __552K__ users\n",
    "- __77K__ businesses\n",
    "- __2.2M__ user reviews\n",
    "\n",
    "When focusing on restaurants alone, there are approximately __55K__ restaurants with approximately __1M__ user reviews written about them.\n",
    "\n",
    "The data is provided in a handful of files in _.json_ format. We'll be using the following files for our demo:\n",
    "- __business.json__ &mdash; _the records for individual businesses_\n",
    "- __review.json__ &mdash; _the records for reviews users wrote about businesses_\n",
    "\n",
    "The files are text files (UTF-8) with one _json object_ per line, each one corresponding to an individual data record. Let's take a look at a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business records consist of _key, value_ pairs containing information about the particular business. A few attributes we'll be interested in for this demo include:\n",
    "- __business\\_id__ &mdash; _unique identifier for businesses_\n",
    "- __categories__ &mdash; _an array containing relevant category values of businesses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business_id': 'FYWN1wneV18bWNgQjJ2GNg', 'name': 'Dental by Design', 'neighborhood': '', 'address': '4855 E Warner Rd, Ste B9', 'city': 'Ahwatukee', 'state': 'AZ', 'postal_code': '85044', 'latitude': 33.3306902, 'longitude': -111.9785992, 'stars': 4.0, 'review_count': 22, 'is_open': 1, 'attributes': {'AcceptsInsurance': True, 'ByAppointmentOnly': True, 'BusinessAcceptsCreditCards': True}, 'categories': ['Dentists', 'General Dentistry', 'Health & Medical', 'Oral Surgeons', 'Cosmetic Dentists', 'Orthodontists'], 'hours': {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:00', 'Thursday': '7:30-17:00', 'Wednesday': '7:30-17:00', 'Monday': '7:30-17:00'}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('business.json', 'r') as f:\n",
    "    first_business_record = json.loads(f.readline())\n",
    "\n",
    "print(first_business_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The review records are stored in a similar manner &mdash; _key, value_ pairs containing information about the reviews. A few attributes of note on the review records:\n",
    "- __business\\_id__ &mdash; _indicates which business the review is about_\n",
    "- __text__ &mdash; _the natural language text the user wrote_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': 'v0i_UHJMo_hPBq9bxWvW4w', 'user_id': 'bv2nCi5Qv5vroFiqKGopiw', 'business_id': '0W4lkclzZThpx3V65bVgig', 'stars': 5, 'date': '2016-05-28', 'text': \"Love the staff, love the meat, love the place. Prepare for a long line around lunch or dinner hours. \\n\\nThey ask you how you want you meat, lean or something maybe, I can't remember. Just say you don't want it too fatty. \\n\\nGet a half sour pickle and a hot pepper. Hand cut french fries too.\", 'useful': 0, 'funny': 0, 'cool': 0}\n"
     ]
    }
   ],
   "source": [
    "with open('review.json', 'r') as f:\n",
    "    first_review_record = json.loads(f.readline())\n",
    "    \n",
    "print(first_review_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below extracts the unique restaurant IDs and counts them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54,618 restaurants in the dataset.\n"
     ]
    }
   ],
   "source": [
    "restaurant_ids = set()\n",
    "\n",
    "# open the businesses file\n",
    "with open('business.json') as f:\n",
    "    \n",
    "    # iterate through each line (json record) in the file\n",
    "    for business_json in f:\n",
    "        \n",
    "        # convert the json record to a Python dict\n",
    "        business = json.loads(business_json)\n",
    "        \n",
    "        # if this business is not a restaurant, skip to the next one\n",
    "        if u'Restaurants' not in business[u'categories']:\n",
    "            continue\n",
    "            \n",
    "        # add the restaurant business id to our restaurant_ids set\n",
    "        restaurant_ids.add(business[u'business_id'])\n",
    "\n",
    "# turn restaurant_ids into a frozenset, as we don't need to change it anymore\n",
    "restaurant_ids = frozenset(restaurant_ids)\n",
    "\n",
    "# print the number of unique restaurant ids in the dataset\n",
    "print('{:,}'.format(len(restaurant_ids)), u'restaurants in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract from the reviews the text relative to restaurant reviews, and only those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text from 31 restaurant reviews \n",
      "         written to the new txt file.\n",
      "CPU times: user 694 µs, sys: 828 µs, total: 1.52 ms\n",
      "Wall time: 785 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "review_txt_filepath = os.path.join('intermediate', 'review_text_all.txt')\n",
    "if os.path.isfile(review_txt_filepath):\n",
    "    with open(review_txt_filepath, 'r') as fh:\n",
    "        for review_count, line in enumerate(review_txt_filepath):\n",
    "            pass\n",
    "else:\n",
    "    review_count = 0\n",
    "\n",
    "    # create & open a new file in write mode\n",
    "    with gzip.open(review_txt_filepath, 'w') as review_txt_filepath:\n",
    "\n",
    "        # open the existing review json file\n",
    "        with gzip.open('review.json') as review_json_file:\n",
    "\n",
    "            # loop through all reviews in the existing file and convert to dict\n",
    "            for review_json in review_json_file:\n",
    "                review = json.loads(review_json)\n",
    "\n",
    "                # if this review is not about a restaurant, skip to the next one\n",
    "                if review[u'business_id'] not in restaurant_ids:\n",
    "                    continue\n",
    "\n",
    "                # write the restaurant review as a line in the new file\n",
    "                # escape newline characters in the original review text\n",
    "                review_txt_filepath.write(review[u'text'].replace('\\n', '\\\\n') + '\\n')\n",
    "                review_count += 1\n",
    "\n",
    "print('''Text from {:,} restaurant reviews \n",
    "         written to the new txt file.'''.format(review_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![spaCy](https://s3.amazonaws.com/skipgram-images/spaCy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**spaCy**](https://spacy.io) is an industrial-strength natural language processing (_NLP_) library for Python. spaCy's goal is to take recent advancements in natural language processing out of research papers and put them in the hands of users to build production software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy contains built-in data and models which you can use out-of-the-box for processing general-purpose English language text:\n",
    "- Large English vocabulary, including stopword lists\n",
    "- Token \"probabilities\"\n",
    "- Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy Can perform\n",
    "- Tokenization\n",
    "- Text normalization, such as lowercasing, stemming/lemmatization\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Sentence boundary detection\n",
    "- Named entity recognition and annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is currently my parents new favourite restaurant. \n",
      "\n",
      "We come here in the morning for dim sum. They are not the cart pushing type of dim sum, it is order off of the sheet. Dim sum is not bad and not expensive either.\n",
      "\n",
      "We also frequent the dinner scene. Their set dinner menu is not bad. We typically order a 6 dish menu and it's big enough to feed a family of 9 with leftovers. \n",
      "\n",
      "Overall, food is pretty tasty!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "with open(review_txt_filepath) as f:\n",
    "    sample_review = list(it.islice(f, 8, 9))[0]\n",
    "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
    "        \n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition into sentences\n",
    "\n",
    "Let's decompose this review into it's language components. First of all, how many sentences is the review composed of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "This is currently my parents new favourite restaurant. \n",
      "\n",
      "\n",
      "\n",
      "Sentence 2:\n",
      "We come here in the morning for dim sum.\n",
      "\n",
      "Sentence 3:\n",
      "They are not the cart pushing type of dim sum, it is order off of the sheet.\n",
      "\n",
      "Sentence 4:\n",
      "Dim sum is not bad and not expensive either.\n",
      "\n",
      "\n",
      "\n",
      "Sentence 5:\n",
      "We also frequent the dinner scene.\n",
      "\n",
      "Sentence 6:\n",
      "Their set dinner menu is not bad.\n",
      "\n",
      "Sentence 7:\n",
      "We typically order a 6 dish menu and it's big enough to feed a family of 9 with leftovers. \n",
      "\n",
      "\n",
      "\n",
      "Sentence 8:\n",
      "Overall, food is pretty tasty!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed_review = nlp(sample_review)\n",
    "\n",
    "for num, sentence in enumerate(parsed_review.sents):\n",
    "    print('Sentence {}:'.format(num + 1))\n",
    "    print(sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named-Entity recognition\n",
    "\n",
    "**GPE** stands for Geo-Political Entity. Apparently the newlines are confusing the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 1: 6 - CARDINAL\n",
      "\n",
      "Entity 2: 9 - CARDINAL\n",
      "\n",
      "Entity 3: \n",
      " - GPE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, entity in enumerate(parsed_review.ents):\n",
    "    print('Entity {}:'.format(num + 1), entity, '-', entity.label_)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts Of Speech (POS) tagging\n",
    "\n",
    "Let's decompose the text into POS tags, like verbs, adverbs, adjectives, punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>part_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parents</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>favourite</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>here</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>morning</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dim</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sum</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>They</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>are</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>not</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cart</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pushing</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>type</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dim</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sum</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>We</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>typically</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>order</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>dish</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>menu</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>'s</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>big</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>enough</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feed</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>family</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>with</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>leftovers</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Overall</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>food</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pretty</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tasty</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text part_of_speech\n",
       "0         This            DET\n",
       "1           is           VERB\n",
       "2    currently            ADV\n",
       "3           my            ADJ\n",
       "4      parents           NOUN\n",
       "5          new            ADJ\n",
       "6    favourite            ADJ\n",
       "7   restaurant           NOUN\n",
       "8            .          PUNCT\n",
       "9         \\n\\n          SPACE\n",
       "10          We           PRON\n",
       "11        come           VERB\n",
       "12        here            ADV\n",
       "13          in            ADP\n",
       "14         the            DET\n",
       "15     morning           NOUN\n",
       "16         for            ADP\n",
       "17         dim            ADJ\n",
       "18         sum           NOUN\n",
       "19           .          PUNCT\n",
       "20        They           PRON\n",
       "21         are           VERB\n",
       "22         not            ADV\n",
       "23         the            DET\n",
       "24        cart           NOUN\n",
       "25     pushing           VERB\n",
       "26        type           NOUN\n",
       "27          of            ADP\n",
       "28         dim            ADJ\n",
       "29         sum           NOUN\n",
       "..         ...            ...\n",
       "65          We           PRON\n",
       "66   typically            ADV\n",
       "67       order           VERB\n",
       "68           a            DET\n",
       "69           6            NUM\n",
       "70        dish           NOUN\n",
       "71        menu           NOUN\n",
       "72         and          CCONJ\n",
       "73          it           PRON\n",
       "74          's           VERB\n",
       "75         big            ADJ\n",
       "76      enough            ADV\n",
       "77          to           PART\n",
       "78        feed           VERB\n",
       "79           a            DET\n",
       "80      family           NOUN\n",
       "81          of            ADP\n",
       "82           9            NUM\n",
       "83        with            ADP\n",
       "84   leftovers           NOUN\n",
       "85           .          PUNCT\n",
       "86        \\n\\n          SPACE\n",
       "87     Overall            ADV\n",
       "88           ,          PUNCT\n",
       "89        food           NOUN\n",
       "90          is           VERB\n",
       "91      pretty            ADV\n",
       "92       tasty            ADJ\n",
       "93           !          PUNCT\n",
       "94          \\n          SPACE\n",
       "\n",
       "[95 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_text = [token.orth_ for token in parsed_review]\n",
    "token_pos = [token.pos_ for token in parsed_review]\n",
    "pd.DataFrame(list(zip(token_text, token_pos)),\n",
    "             columns=['token_text', 'part_of_speech'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming, lemmatization, shape analysis\n",
    "\n",
    "Note that `is` is lemmatized into `be`. Plurals are stemmed into singulars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>Xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently</td>\n",
       "      <td>currently</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parents</td>\n",
       "      <td>parent</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>favourite</td>\n",
       "      <td>favourite</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>Xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>come</td>\n",
       "      <td>come</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>here</td>\n",
       "      <td>here</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dim</td>\n",
       "      <td>dim</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sum</td>\n",
       "      <td>sum</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>They</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>Xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>are</td>\n",
       "      <td>be</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cart</td>\n",
       "      <td>cart</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pushing</td>\n",
       "      <td>push</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>type</td>\n",
       "      <td>type</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dim</td>\n",
       "      <td>dim</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sum</td>\n",
       "      <td>sum</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>We</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>Xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>typically</td>\n",
       "      <td>typically</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>order</td>\n",
       "      <td>order</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>dish</td>\n",
       "      <td>dish</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>menu</td>\n",
       "      <td>menu</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>it</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>'s</td>\n",
       "      <td>be</td>\n",
       "      <td>'x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>big</td>\n",
       "      <td>big</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feed</td>\n",
       "      <td>feed</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>family</td>\n",
       "      <td>family</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>leftovers</td>\n",
       "      <td>leftover</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Overall</td>\n",
       "      <td>overall</td>\n",
       "      <td>Xxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pretty</td>\n",
       "      <td>pretty</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tasty</td>\n",
       "      <td>tasty</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_text token_lemma token_shape\n",
       "0         This        this        Xxxx\n",
       "1           is          be          xx\n",
       "2    currently   currently        xxxx\n",
       "3           my      -PRON-          xx\n",
       "4      parents      parent        xxxx\n",
       "5          new         new         xxx\n",
       "6    favourite   favourite        xxxx\n",
       "7   restaurant  restaurant        xxxx\n",
       "8            .           .           .\n",
       "9         \\n\\n        \\n\\n        \\n\\n\n",
       "10          We      -PRON-          Xx\n",
       "11        come        come        xxxx\n",
       "12        here        here        xxxx\n",
       "13          in          in          xx\n",
       "14         the         the         xxx\n",
       "15     morning     morning        xxxx\n",
       "16         for         for         xxx\n",
       "17         dim         dim         xxx\n",
       "18         sum         sum         xxx\n",
       "19           .           .           .\n",
       "20        They      -PRON-        Xxxx\n",
       "21         are          be         xxx\n",
       "22         not         not         xxx\n",
       "23         the         the         xxx\n",
       "24        cart        cart        xxxx\n",
       "25     pushing        push        xxxx\n",
       "26        type        type        xxxx\n",
       "27          of          of          xx\n",
       "28         dim         dim         xxx\n",
       "29         sum         sum         xxx\n",
       "..         ...         ...         ...\n",
       "65          We      -PRON-          Xx\n",
       "66   typically   typically        xxxx\n",
       "67       order       order        xxxx\n",
       "68           a           a           x\n",
       "69           6           6           d\n",
       "70        dish        dish        xxxx\n",
       "71        menu        menu        xxxx\n",
       "72         and         and         xxx\n",
       "73          it      -PRON-          xx\n",
       "74          's          be          'x\n",
       "75         big         big         xxx\n",
       "76      enough      enough        xxxx\n",
       "77          to          to          xx\n",
       "78        feed        feed        xxxx\n",
       "79           a           a           x\n",
       "80      family      family        xxxx\n",
       "81          of          of          xx\n",
       "82           9           9           d\n",
       "83        with        with        xxxx\n",
       "84   leftovers    leftover        xxxx\n",
       "85           .           .           .\n",
       "86        \\n\\n        \\n\\n        \\n\\n\n",
       "87     Overall     overall       Xxxxx\n",
       "88           ,           ,           ,\n",
       "89        food        food        xxxx\n",
       "90          is          be          xx\n",
       "91      pretty      pretty        xxxx\n",
       "92       tasty       tasty        xxxx\n",
       "93           !           !           !\n",
       "94          \\n          \\n          \\n\n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemma = [token.lemma_ for token in parsed_review]\n",
    "token_shape = [token.shape_ for token in parsed_review]\n",
    "\n",
    "pd.DataFrame(list(zip(token_text, token_lemma, token_shape)),\n",
    "             columns=['token_text', 'token_lemma', 'token_shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the relative frequency of certain types of token:\n",
    "- stopword\n",
    "- punctuation\n",
    "- whitespace\n",
    "- represents a number\n",
    "- whether or not the token is included in spaCy's default vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stop?</th>\n",
       "      <th>punctuation?</th>\n",
       "      <th>whitespace?</th>\n",
       "      <th>number?</th>\n",
       "      <th>in vocab.?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currently</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parents</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>new</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>favourite</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restaurant</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>come</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>here</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>morning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>for</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dim</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sum</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>They</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>are</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>not</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cart</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pushing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>type</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>of</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dim</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sum</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>We</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>typically</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>order</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>a</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>dish</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>menu</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>and</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>it</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>'s</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>big</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>enough</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>to</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>feed</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>a</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>family</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>of</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>with</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>leftovers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Overall</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>food</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>is</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>pretty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>tasty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>!</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          text stop? punctuation? whitespace? number? in vocab.?\n",
       "0         This                                               Yes\n",
       "1           is   Yes                                         Yes\n",
       "2    currently                                               Yes\n",
       "3           my   Yes                                         Yes\n",
       "4      parents                                               Yes\n",
       "5          new                                               Yes\n",
       "6    favourite                                               Yes\n",
       "7   restaurant                                               Yes\n",
       "8            .                Yes                            Yes\n",
       "9         \\n\\n                            Yes                Yes\n",
       "10          We                                               Yes\n",
       "11        come                                               Yes\n",
       "12        here   Yes                                         Yes\n",
       "13          in   Yes                                         Yes\n",
       "14         the   Yes                                         Yes\n",
       "15     morning                                               Yes\n",
       "16         for   Yes                                         Yes\n",
       "17         dim                                               Yes\n",
       "18         sum                                               Yes\n",
       "19           .                Yes                            Yes\n",
       "20        They                                               Yes\n",
       "21         are   Yes                                         Yes\n",
       "22         not   Yes                                         Yes\n",
       "23         the   Yes                                         Yes\n",
       "24        cart                                               Yes\n",
       "25     pushing                                               Yes\n",
       "26        type                                               Yes\n",
       "27          of   Yes                                         Yes\n",
       "28         dim                                               Yes\n",
       "29         sum                                               Yes\n",
       "..         ...   ...          ...         ...     ...        ...\n",
       "65          We                                               Yes\n",
       "66   typically                                               Yes\n",
       "67       order                                               Yes\n",
       "68           a   Yes                                         Yes\n",
       "69           6                                    Yes        Yes\n",
       "70        dish                                               Yes\n",
       "71        menu                                               Yes\n",
       "72         and   Yes                                         Yes\n",
       "73          it   Yes                                         Yes\n",
       "74          's                                               Yes\n",
       "75         big                                               Yes\n",
       "76      enough   Yes                                         Yes\n",
       "77          to   Yes                                         Yes\n",
       "78        feed                                               Yes\n",
       "79           a   Yes                                         Yes\n",
       "80      family                                               Yes\n",
       "81          of   Yes                                         Yes\n",
       "82           9                                    Yes        Yes\n",
       "83        with   Yes                                         Yes\n",
       "84   leftovers                                               Yes\n",
       "85           .                Yes                            Yes\n",
       "86        \\n\\n                            Yes                Yes\n",
       "87     Overall                                               Yes\n",
       "88           ,                Yes                            Yes\n",
       "89        food                                               Yes\n",
       "90          is   Yes                                         Yes\n",
       "91      pretty                                               Yes\n",
       "92       tasty                                               Yes\n",
       "93           !                Yes                            Yes\n",
       "94          \\n                            Yes                Yes\n",
       "\n",
       "[95 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attributes = [(token.orth_,\n",
    "                     # token.prob,\n",
    "                     token.is_stop,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.like_num,\n",
    "                     token.is_oov)\n",
    "                    for token in parsed_review]\n",
    "\n",
    "df = pd.DataFrame(token_attributes,\n",
    "                  columns=['text',\n",
    "                           # 'log_probability',\n",
    "                           'stop?',\n",
    "                           'punctuation?',\n",
    "                           'whitespace?',\n",
    "                           'number?',\n",
    "                           'in vocab.?'])\n",
    "\n",
    "df.loc[:, 'stop?':'in vocab.?'] = (df.loc[:, 'stop?':'in vocab.?']\n",
    "                                       .applymap(lambda x: u'Yes' if x else u''))\n",
    "                                               \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that all this works because the text is *generic*. If we had clinical, medical, or other technical language, SpaCy would struggle. This can be remediated, but this is outside of the scope of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modeling\n",
    "\n",
    "So far we have considered single words. Words that often co-occur together can refer to a single entity (e.g. 'New' and 'York' and 'City' refer to one concept, not three). The Chinese food *dim sum* was actually interpreted as the two English words *dim* and *sum*.\n",
    "We compare the frequency of the occurrence of words `A` and `B` separately, with the frequency of occurrences of the word-pair `A B`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below:\n",
    "1. Check whether a word is punctuation or whitespace.\n",
    "2. WHAT DO THEY DO????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename)):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 593 µs, sys: 1.1 ms, total: 1.69 ms\n",
      "Wall time: 6.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unigram_sentences_filepath = os.path.join('intermediate', 'unigram_sentences_all.txt')\n",
    "\n",
    "if not os.path.isfile(unigram_sentences_filepath):  \n",
    "    with open(unigram_sentences_filepath, 'w') as f:\n",
    "        for sentence in lemmatized_sentence_corpus(review_txt_filepath):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
